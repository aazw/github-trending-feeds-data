<?xml version='1.0' encoding='utf-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <id>https://aazw.github.io/github-trending-feeds/feeds/jupyter-notebook/daily.atom</id>
  <title>GitHub Trending - jupyter-notebook (daily)</title>
  <link href="https://aazw.github.io/github-trending-feeds/feeds/jupyter-notebook/daily.atom" rel="self" />
  <link href="https://aazw.github.io/github-trending-feeds/" rel="alternate" />
  <icon>https://github.githubassets.com/favicons/favicon.svg</icon>
  <updated>2025-01-15T11:18:13+00:00</updated>
  <author>
    <name>aazw</name>
  </author>
  <entry>
    <id>https://github.com/OpenBMB/MiniCPM#1736939893</id>
    <title>https://github.com/OpenBMB/MiniCPM</title>
    <link href="https://github.com/OpenBMB/MiniCPM" />
    <updated>2025-01-15T11:18:13+00:00</updated>
    <content type="text">MiniCPM3-4B: An edge-side LLM that surpasses GPT-3.5-Turbo.</content>
  </entry>
  <entry>
    <id>https://github.com/IDEA-Research/Grounded-SAM-2#1736939893</id>
    <title>https://github.com/IDEA-Research/Grounded-SAM-2</title>
    <link href="https://github.com/IDEA-Research/Grounded-SAM-2" />
    <updated>2025-01-15T11:18:13+00:00</updated>
    <content type="text">Grounded SAM 2: Ground and Track Anything in Videos with Grounding DINO, Florence-2 and SAM 2</content>
  </entry>
  <entry>
    <id>https://github.com/aws/amazon-sagemaker-examples#1736939893</id>
    <title>https://github.com/aws/amazon-sagemaker-examples</title>
    <link href="https://github.com/aws/amazon-sagemaker-examples" />
    <updated>2025-01-15T11:18:13+00:00</updated>
    <content type="text">Example ğŸ““ Jupyter notebooks that demonstrate how to build, train, and deploy machine learning models using ğŸ§  Amazon SageMaker.</content>
  </entry>
  <entry>
    <id>https://github.com/dusty-nv/jetson-containers#1736939893</id>
    <title>https://github.com/dusty-nv/jetson-containers</title>
    <link href="https://github.com/dusty-nv/jetson-containers" />
    <updated>2025-01-15T11:18:13+00:00</updated>
    <content type="text">Machine Learning Containers for NVIDIA Jetson and JetPack-L4T</content>
  </entry>
  <entry>
    <id>https://github.com/openai/CLIP#1736939893</id>
    <title>https://github.com/openai/CLIP</title>
    <link href="https://github.com/openai/CLIP" />
    <updated>2025-01-15T11:18:13+00:00</updated>
    <content type="text">CLIP (Contrastive Language-Image Pretraining), Predict the most relevant text snippet given an image</content>
  </entry>
  <entry>
    <id>https://github.com/google-gemini/cookbook#1736939893</id>
    <title>https://github.com/google-gemini/cookbook</title>
    <link href="https://github.com/google-gemini/cookbook" />
    <updated>2025-01-15T11:18:13+00:00</updated>
    <content type="text">Examples and guides for using the Gemini API</content>
  </entry>
  <entry>
    <id>https://github.com/aws-samples/amazon-bedrock-samples#1736939893</id>
    <title>https://github.com/aws-samples/amazon-bedrock-samples</title>
    <link href="https://github.com/aws-samples/amazon-bedrock-samples" />
    <updated>2025-01-15T11:18:13+00:00</updated>
    <content type="text">This repository contains examples for customers to get started using the Amazon Bedrock Service. This contains examples for all available foundational models</content>
  </entry>
  <entry>
    <id>https://github.com/langchain-ai/langchain-academy#1736939893</id>
    <title>https://github.com/langchain-ai/langchain-academy</title>
    <link href="https://github.com/langchain-ai/langchain-academy" />
    <updated>2025-01-15T11:18:13+00:00</updated>
    <content type="text" />
  </entry>
  <entry>
    <id>https://github.com/wesm/pydata-book#1736939893</id>
    <title>https://github.com/wesm/pydata-book</title>
    <link href="https://github.com/wesm/pydata-book" />
    <updated>2025-01-15T11:18:13+00:00</updated>
    <content type="text">Materials and IPython notebooks for "Python for Data Analysis" by Wes McKinney, published by O'Reilly Media</content>
  </entry>
  <entry>
    <id>https://github.com/datawhalechina/llm-universe#1736939893</id>
    <title>https://github.com/datawhalechina/llm-universe</title>
    <link href="https://github.com/datawhalechina/llm-universe" />
    <updated>2025-01-15T11:18:13+00:00</updated>
    <content type="text">æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªé¢å‘å°ç™½å¼€å‘è€…çš„å¤§æ¨¡å‹åº”ç”¨å¼€å‘æ•™ç¨‹ï¼Œåœ¨çº¿é˜…è¯»åœ°å€ï¼šhttps://datawhalechina.github.io/llm-universe/</content>
  </entry>
  <entry>
    <id>https://github.com/embeddings-benchmark/mteb#1736939893</id>
    <title>https://github.com/embeddings-benchmark/mteb</title>
    <link href="https://github.com/embeddings-benchmark/mteb" />
    <updated>2025-01-15T11:18:13+00:00</updated>
    <content type="text">MTEB: Massive Text Embedding Benchmark</content>
  </entry>
  <entry>
    <id>https://github.com/facebookresearch/dinov2#1736939893</id>
    <title>https://github.com/facebookresearch/dinov2</title>
    <link href="https://github.com/facebookresearch/dinov2" />
    <updated>2025-01-15T11:18:13+00:00</updated>
    <content type="text">PyTorch code and models for the DINOv2 self-supervised learning method.</content>
  </entry>
  <entry>
    <id>https://github.com/microsoft/OmniParser#1736939893</id>
    <title>https://github.com/microsoft/OmniParser</title>
    <link href="https://github.com/microsoft/OmniParser" />
    <updated>2025-01-15T11:18:13+00:00</updated>
    <content type="text">A simple screen parsing tool towards pure vision based GUI agent</content>
  </entry>
</feed>