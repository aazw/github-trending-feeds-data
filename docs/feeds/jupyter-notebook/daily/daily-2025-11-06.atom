<?xml version='1.0' encoding='utf-8'?>
<ns0:feed xmlns:ns0="http://www.w3.org/2005/Atom" xml:lang="en">
  <ns0:id>https://aazw.github.io/github-trending-feeds/feeds/jupyter-notebook/daily.atom</ns0:id>
  <ns0:title>GitHub Trending - jupyter-notebook (daily)</ns0:title>
  <ns0:link href="https://aazw.github.io/github-trending-feeds/feeds/jupyter-notebook/daily.atom" rel="self"/>
  <ns0:link href="https://aazw.github.io/github-trending-feeds/" rel="alternate"/>
  <ns0:icon>https://github.githubassets.com/favicons/favicon.svg</ns0:icon>
  <ns0:updated>2025-11-06T00:00:00</ns0:updated>
  <ns0:author>
    <ns0:name>aazw</ns0:name>
  </ns0:author>
  <ns0:entry>
    <ns0:id>urn:github:GoogleCloudPlatform:vertex-ai-creative-studio:1762387200</ns0:id>
    <ns0:title>GoogleCloudPlatform/vertex-ai-creative-studio</ns0:title>
    <ns0:link href="https://github.com/GoogleCloudPlatform/vertex-ai-creative-studio"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/GoogleCloudPlatform/vertex-ai-creative-studio"&gt;https://github.com/GoogleCloudPlatform/vertex-ai-creative-studio&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;GenMedia Creative Studio is a Vertex AI generative media user experience highlighting the use of Imagen, Veo, Gemini üçå, Gemini TTS, Chirp 3, Lyria and other generative media APIs on Google Cloud.&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:HandsOnLLM:Hands-On-Large-Language-Models:1762387200</ns0:id>
    <ns0:title>HandsOnLLM/Hands-On-Large-Language-Models</ns0:title>
    <ns0:link href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models"&gt;https://github.com/HandsOnLLM/Hands-On-Large-Language-Models&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Official code repo for the O'Reilly Book - "Hands-On Large Language Models"&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:IDEA-Research:Grounded-SAM-2:1762387200</ns0:id>
    <ns0:title>IDEA-Research/Grounded-SAM-2</ns0:title>
    <ns0:link href="https://github.com/IDEA-Research/Grounded-SAM-2"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/IDEA-Research/Grounded-SAM-2"&gt;https://github.com/IDEA-Research/Grounded-SAM-2&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Grounded SAM 2: Ground and Track Anything in Videos with Grounding DINO, Florence-2 and SAM 2&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:Lifelong-Robot-Learning:LIBERO:1762387200</ns0:id>
    <ns0:title>Lifelong-Robot-Learning/LIBERO</ns0:title>
    <ns0:link href="https://github.com/Lifelong-Robot-Learning/LIBERO"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/Lifelong-Robot-Learning/LIBERO"&gt;https://github.com/Lifelong-Robot-Learning/LIBERO&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Benchmarking Knowledge Transfer in Lifelong Robot Learning&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:NirDiamant:GenAI_Agents:1762387200</ns0:id>
    <ns0:title>NirDiamant/GenAI_Agents</ns0:title>
    <ns0:link href="https://github.com/NirDiamant/GenAI_Agents"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/NirDiamant/GenAI_Agents"&gt;https://github.com/NirDiamant/GenAI_Agents&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;This repository provides tutorials and implementations for various Generative AI Agent techniques, from basic to advanced. It serves as a comprehensive guide for building intelligent, interactive AI systems.&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:NirDiamant:RAG_Techniques:1762387200</ns0:id>
    <ns0:title>NirDiamant/RAG_Techniques</ns0:title>
    <ns0:link href="https://github.com/NirDiamant/RAG_Techniques"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/NirDiamant/RAG_Techniques"&gt;https://github.com/NirDiamant/RAG_Techniques&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:awslabs:amazon-bedrock-agentcore-samples:1762387200</ns0:id>
    <ns0:title>awslabs/amazon-bedrock-agentcore-samples</ns0:title>
    <ns0:link href="https://github.com/awslabs/amazon-bedrock-agentcore-samples"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/awslabs/amazon-bedrock-agentcore-samples"&gt;https://github.com/awslabs/amazon-bedrock-agentcore-samples&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Amazon Bedrock Agentcore accelerates AI agents into production with the scale, reliability, and security, critical to real-world deployment.&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:datawhalechina:easy-rl:1762387200</ns0:id>
    <ns0:title>datawhalechina/easy-rl</ns0:title>
    <ns0:link href="https://github.com/datawhalechina/easy-rl"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/datawhalechina/easy-rl"&gt;https://github.com/datawhalechina/easy-rl&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Âº∫ÂåñÂ≠¶‰π†‰∏≠ÊñáÊïôÁ®ãÔºàËòëËèá‰π¶üçÑÔºâÔºåÂú®Á∫øÈòÖËØªÂú∞ÂùÄÔºöhttps://datawhalechina.github.io/easy-rl/&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:datawhalechina:happy-llm:1762387200</ns0:id>
    <ns0:title>datawhalechina/happy-llm</ns0:title>
    <ns0:link href="https://github.com/datawhalechina/happy-llm"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/datawhalechina/happy-llm"&gt;https://github.com/datawhalechina/happy-llm&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;üìö ‰ªéÈõ∂ÂºÄÂßãÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂéüÁêÜ‰∏éÂÆûË∑µÊïôÁ®ã&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:digitalinnovationone:dio-lab-open-source:1762387200</ns0:id>
    <ns0:title>digitalinnovationone/dio-lab-open-source</ns0:title>
    <ns0:link href="https://github.com/digitalinnovationone/dio-lab-open-source"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/digitalinnovationone/dio-lab-open-source"&gt;https://github.com/digitalinnovationone/dio-lab-open-source&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Reposit√≥rio do lab "Contribuindo em um Projeto Open Source no GitHub" da Digital Innovation One.&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:facebookresearch:sam2:1762387200</ns0:id>
    <ns0:title>facebookresearch/sam2</ns0:title>
    <ns0:link href="https://github.com/facebookresearch/sam2"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/facebookresearch/sam2"&gt;https://github.com/facebookresearch/sam2&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;The repository provides code for running inference with the Meta Segment Anything Model 2 (SAM 2), links for downloading the trained model checkpoints, and example notebooks that show how to use the model.&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:google-research:vision_transformer:1762387200</ns0:id>
    <ns0:title>google-research/vision_transformer</ns0:title>
    <ns0:link href="https://github.com/google-research/vision_transformer"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/google-research/vision_transformer"&gt;https://github.com/google-research/vision_transformer&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:jackfrued:Python-100-Days:1762387200</ns0:id>
    <ns0:title>jackfrued/Python-100-Days</ns0:title>
    <ns0:link href="https://github.com/jackfrued/Python-100-Days"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/jackfrued/Python-100-Days"&gt;https://github.com/jackfrued/Python-100-Days&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Python - 100Â§©‰ªéÊñ∞ÊâãÂà∞Â§ßÂ∏à&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:karpathy:nn-zero-to-hero:1762387200</ns0:id>
    <ns0:title>karpathy/nn-zero-to-hero</ns0:title>
    <ns0:link href="https://github.com/karpathy/nn-zero-to-hero"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/karpathy/nn-zero-to-hero"&gt;https://github.com/karpathy/nn-zero-to-hero&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Neural Networks: Zero to Hero&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:mml-book:mml-book.github.io:1762387200</ns0:id>
    <ns0:title>mml-book/mml-book.github.io</ns0:title>
    <ns0:link href="https://github.com/mml-book/mml-book.github.io"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/mml-book/mml-book.github.io"&gt;https://github.com/mml-book/mml-book.github.io&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Companion webpage to the book "Mathematics For Machine Learning"&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:vandijklab:cell2sentence:1762387200</ns0:id>
    <ns0:title>vandijklab/cell2sentence</ns0:title>
    <ns0:link href="https://github.com/vandijklab/cell2sentence"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/vandijklab/cell2sentence"&gt;https://github.com/vandijklab/cell2sentence&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Cell2Sentence: Teaching Large Language Models the Language of Biology&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:zju3dv:GVHMR:1762387200</ns0:id>
    <ns0:title>zju3dv/GVHMR</ns0:title>
    <ns0:link href="https://github.com/zju3dv/GVHMR"/>
    <ns0:updated>2025-11-06T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/zju3dv/GVHMR"&gt;https://github.com/zju3dv/GVHMR&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Code for "GVHMR: World-Grounded Human Motion Recovery via Gravity-View Coordinates", Siggraph Asia 2024&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
</ns0:feed>