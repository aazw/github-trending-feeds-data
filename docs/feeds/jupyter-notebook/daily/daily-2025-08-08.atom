<?xml version='1.0' encoding='utf-8'?>
<ns0:feed xmlns:ns0="http://www.w3.org/2005/Atom" xml:lang="en">
  <ns0:id>https://aazw.github.io/github-trending-feeds/feeds/jupyter-notebook/daily.atom</ns0:id>
  <ns0:title>GitHub Trending - jupyter-notebook (daily)</ns0:title>
  <ns0:link href="https://aazw.github.io/github-trending-feeds/feeds/jupyter-notebook/daily.atom" rel="self"/>
  <ns0:link href="https://aazw.github.io/github-trending-feeds/" rel="alternate"/>
  <ns0:icon>https://github.githubassets.com/favicons/favicon.svg</ns0:icon>
  <ns0:updated>2025-08-08T00:00:00</ns0:updated>
  <ns0:author>
    <ns0:name>aazw</ns0:name>
  </ns0:author>
  <ns0:entry>
    <ns0:id>urn:github:HandsOnLLM:Hands-On-Large-Language-Models:1754611200</ns0:id>
    <ns0:title>HandsOnLLM/Hands-On-Large-Language-Models</ns0:title>
    <ns0:link href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/HandsOnLLM/Hands-On-Large-Language-Models"&gt;https://github.com/HandsOnLLM/Hands-On-Large-Language-Models&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Official code repo for the O'Reilly Book - "Hands-On Large Language Models"&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:IDEA-Research:Grounded-SAM-2:1754611200</ns0:id>
    <ns0:title>IDEA-Research/Grounded-SAM-2</ns0:title>
    <ns0:link href="https://github.com/IDEA-Research/Grounded-SAM-2"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/IDEA-Research/Grounded-SAM-2"&gt;https://github.com/IDEA-Research/Grounded-SAM-2&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Grounded SAM 2: Ground and Track Anything in Videos with Grounding DINO, Florence-2 and SAM 2&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:QwenLM:Qwen2.5-Omni:1754611200</ns0:id>
    <ns0:title>QwenLM/Qwen2.5-Omni</ns0:title>
    <ns0:link href="https://github.com/QwenLM/Qwen2.5-Omni"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/QwenLM/Qwen2.5-Omni"&gt;https://github.com/QwenLM/Qwen2.5-Omni&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Qwen2.5-Omni is an end-to-end multimodal model by Qwen team at Alibaba Cloud, capable of understanding text, audio, vision, video, and performing real-time speech generation.&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:anthropics:prompt-eng-interactive-tutorial:1754611200</ns0:id>
    <ns0:title>anthropics/prompt-eng-interactive-tutorial</ns0:title>
    <ns0:link href="https://github.com/anthropics/prompt-eng-interactive-tutorial"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/anthropics/prompt-eng-interactive-tutorial"&gt;https://github.com/anthropics/prompt-eng-interactive-tutorial&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Anthropic's Interactive Prompt Engineering Tutorial&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:datawhalechina:self-llm:1754611200</ns0:id>
    <ns0:title>datawhalechina/self-llm</ns0:title>
    <ns0:link href="https://github.com/datawhalechina/self-llm"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/datawhalechina/self-llm"&gt;https://github.com/datawhalechina/self-llm&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;《开源大模型食用指南》针对中国宝宝量身打造的基于Linux环境快速微调（全参数/Lora）、部署国内外开源大模型（LLM）/多模态大模型（MLLM）教程&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:google-deepmind:mujoco:1754611200</ns0:id>
    <ns0:title>google-deepmind/mujoco</ns0:title>
    <ns0:link href="https://github.com/google-deepmind/mujoco"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/google-deepmind/mujoco"&gt;https://github.com/google-deepmind/mujoco&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Multi-Joint dynamics with Contact. A general purpose physics simulator.&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:jonkrohn:ML-foundations:1754611200</ns0:id>
    <ns0:title>jonkrohn/ML-foundations</ns0:title>
    <ns0:link href="https://github.com/jonkrohn/ML-foundations"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/jonkrohn/ML-foundations"&gt;https://github.com/jonkrohn/ML-foundations&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Machine Learning Foundations: Linear Algebra, Calculus, Statistics &amp; Computer Science&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:langchain-ai:langchain:1754611200</ns0:id>
    <ns0:title>langchain-ai/langchain</ns0:title>
    <ns0:link href="https://github.com/langchain-ai/langchain"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/langchain-ai/langchain"&gt;https://github.com/langchain-ai/langchain&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;🦜🔗 Build context-aware reasoning applications&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:microsoft:Data-Science-For-Beginners:1754611200</ns0:id>
    <ns0:title>microsoft/Data-Science-For-Beginners</ns0:title>
    <ns0:link href="https://github.com/microsoft/Data-Science-For-Beginners"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/microsoft/Data-Science-For-Beginners"&gt;https://github.com/microsoft/Data-Science-For-Beginners&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;10 Weeks, 20 Lessons, Data Science for All!&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:mrdbourke:pytorch-deep-learning:1754611200</ns0:id>
    <ns0:title>mrdbourke/pytorch-deep-learning</ns0:title>
    <ns0:link href="https://github.com/mrdbourke/pytorch-deep-learning"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/mrdbourke/pytorch-deep-learning"&gt;https://github.com/mrdbourke/pytorch-deep-learning&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Materials for the Learn PyTorch for Deep Learning: Zero to Mastery course.&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:openai:CLIP:1754611200</ns0:id>
    <ns0:title>openai/CLIP</ns0:title>
    <ns0:link href="https://github.com/openai/CLIP"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/openai/CLIP"&gt;https://github.com/openai/CLIP&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;CLIP (Contrastive Language-Image Pretraining), Predict the most relevant text snippet given an image&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:openai:openai-cookbook:1754611200</ns0:id>
    <ns0:title>openai/openai-cookbook</ns0:title>
    <ns0:link href="https://github.com/openai/openai-cookbook"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/openai/openai-cookbook"&gt;https://github.com/openai/openai-cookbook&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Examples and guides for using the OpenAI API&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:oreilly-japan:deep-learning-from-scratch:1754611200</ns0:id>
    <ns0:title>oreilly-japan/deep-learning-from-scratch</ns0:title>
    <ns0:link href="https://github.com/oreilly-japan/deep-learning-from-scratch"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/oreilly-japan/deep-learning-from-scratch"&gt;https://github.com/oreilly-japan/deep-learning-from-scratch&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;『ゼロから作る Deep Learning』(O'Reilly Japan, 2016)&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:pyannote:pyannote-audio:1754611200</ns0:id>
    <ns0:title>pyannote/pyannote-audio</ns0:title>
    <ns0:link href="https://github.com/pyannote/pyannote-audio"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/pyannote/pyannote-audio"&gt;https://github.com/pyannote/pyannote-audio&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Neural building blocks for speaker diarization: speech activity detection, speaker change detection, overlapped speech detection, speaker embedding&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:rlabbe:Kalman-and-Bayesian-Filters-in-Python:1754611200</ns0:id>
    <ns0:title>rlabbe/Kalman-and-Bayesian-Filters-in-Python</ns0:title>
    <ns0:link href="https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python"&gt;https://github.com/rlabbe/Kalman-and-Bayesian-Filters-in-Python&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Kalman Filter book using Jupyter Notebook. Focuses on building intuition and experience, not formal proofs. Includes Kalman filters,extended Kalman filters, unscented Kalman filters, particle filters, and more. All exercises include solutions.&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:yandexdataschool:nlp_course:1754611200</ns0:id>
    <ns0:title>yandexdataschool/nlp_course</ns0:title>
    <ns0:link href="https://github.com/yandexdataschool/nlp_course"/>
    <ns0:updated>2025-08-08T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/yandexdataschool/nlp_course"&gt;https://github.com/yandexdataschool/nlp_course&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; jupyter-notebook&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;YSDA course in Natural Language Processing&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
</ns0:feed>