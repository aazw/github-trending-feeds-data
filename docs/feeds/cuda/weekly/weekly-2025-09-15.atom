<?xml version='1.0' encoding='utf-8'?>
<ns0:feed xmlns:ns0="http://www.w3.org/2005/Atom" xml:lang="en">
  <ns0:id>https://aazw.github.io/github-trending-feeds/feeds/cuda/weekly.atom</ns0:id>
  <ns0:title>GitHub Trending - cuda (weekly)</ns0:title>
  <ns0:link href="https://aazw.github.io/github-trending-feeds/feeds/cuda/weekly.atom" rel="self"/>
  <ns0:link href="https://aazw.github.io/github-trending-feeds/" rel="alternate"/>
  <ns0:icon>https://github.githubassets.com/favicons/favicon.svg</ns0:icon>
  <ns0:updated>2025-09-15T00:00:00</ns0:updated>
  <ns0:author>
    <ns0:name>aazw</ns0:name>
  </ns0:author>
  <ns0:entry>
    <ns0:id>urn:github:Dao-AILab:causal-conv1d:1757894400</ns0:id>
    <ns0:title>Dao-AILab/causal-conv1d</ns0:title>
    <ns0:link href="https://github.com/Dao-AILab/causal-conv1d"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/Dao-AILab/causal-conv1d"&gt;https://github.com/Dao-AILab/causal-conv1d&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Causal depthwise conv1d in CUDA, with a PyTorch interface&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:HazyResearch:ThunderKittens:1757894400</ns0:id>
    <ns0:title>HazyResearch/ThunderKittens</ns0:title>
    <ns0:link href="https://github.com/HazyResearch/ThunderKittens"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/HazyResearch/ThunderKittens"&gt;https://github.com/HazyResearch/ThunderKittens&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Tile primitives for speedy kernels&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:HenryHuYu:DiffPhysDrone:1757894400</ns0:id>
    <ns0:title>HenryHuYu/DiffPhysDrone</ns0:title>
    <ns0:link href="https://github.com/HenryHuYu/DiffPhysDrone"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/HenryHuYu/DiffPhysDrone"&gt;https://github.com/HenryHuYu/DiffPhysDrone&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:NVIDIA:CUDALibrarySamples:1757894400</ns0:id>
    <ns0:title>NVIDIA/CUDALibrarySamples</ns0:title>
    <ns0:link href="https://github.com/NVIDIA/CUDALibrarySamples"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/NVIDIA/CUDALibrarySamples"&gt;https://github.com/NVIDIA/CUDALibrarySamples&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;CUDA Library Samples&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:NVIDIA:cub:1757894400</ns0:id>
    <ns0:title>NVIDIA/cub</ns0:title>
    <ns0:link href="https://github.com/NVIDIA/cub"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/NVIDIA/cub"&gt;https://github.com/NVIDIA/cub&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;[ARCHIVED] Cooperative primitives for CUDA C++. See https://github.com/NVIDIA/cccl&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:NVIDIA:nccl-tests:1757894400</ns0:id>
    <ns0:title>NVIDIA/nccl-tests</ns0:title>
    <ns0:link href="https://github.com/NVIDIA/nccl-tests"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/NVIDIA/nccl-tests"&gt;https://github.com/NVIDIA/nccl-tests&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;NCCL Tests&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:NVIDIA:nvbench:1757894400</ns0:id>
    <ns0:title>NVIDIA/nvbench</ns0:title>
    <ns0:link href="https://github.com/NVIDIA/nvbench"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/NVIDIA/nvbench"&gt;https://github.com/NVIDIA/nvbench&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;CUDA Kernel Benchmarking Library&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:NVlabs:instant-ngp:1757894400</ns0:id>
    <ns0:title>NVlabs/instant-ngp</ns0:title>
    <ns0:link href="https://github.com/NVlabs/instant-ngp"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/NVlabs/instant-ngp"&gt;https://github.com/NVlabs/instant-ngp&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Instant neural graphics primitives: lightning fast NeRF and more&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:ROCm:rocm-examples:1757894400</ns0:id>
    <ns0:title>ROCm/rocm-examples</ns0:title>
    <ns0:link href="https://github.com/ROCm/rocm-examples"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/ROCm/rocm-examples"&gt;https://github.com/ROCm/rocm-examples&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;A collection of examples for the ROCm software stack&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:Tony-Tan:CUDA_Freshman:1757894400</ns0:id>
    <ns0:title>Tony-Tan/CUDA_Freshman</ns0:title>
    <ns0:link href="https://github.com/Tony-Tan/CUDA_Freshman"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/Tony-Tan/CUDA_Freshman"&gt;https://github.com/Tony-Tan/CUDA_Freshman&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:brucefan1983:CUDA-Programming:1757894400</ns0:id>
    <ns0:title>brucefan1983/CUDA-Programming</ns0:title>
    <ns0:link href="https://github.com/brucefan1983/CUDA-Programming"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/brucefan1983/CUDA-Programming"&gt;https://github.com/brucefan1983/CUDA-Programming&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Sample codes for my CUDA programming book&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:deepseek-ai:DeepEP:1757894400</ns0:id>
    <ns0:title>deepseek-ai/DeepEP</ns0:title>
    <ns0:link href="https://github.com/deepseek-ai/DeepEP"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/deepseek-ai/DeepEP"&gt;https://github.com/deepseek-ai/DeepEP&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;DeepEP: an efficient expert-parallel communication library&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:deepseek-ai:DeepGEMM:1757894400</ns0:id>
    <ns0:title>deepseek-ai/DeepGEMM</ns0:title>
    <ns0:link href="https://github.com/deepseek-ai/DeepGEMM"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/deepseek-ai/DeepGEMM"&gt;https://github.com/deepseek-ai/DeepGEMM&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;DeepGEMM: clean and efficient FP8 GEMM kernels with fine-grained scaling&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:flashinfer-ai:flashinfer:1757894400</ns0:id>
    <ns0:title>flashinfer-ai/flashinfer</ns0:title>
    <ns0:link href="https://github.com/flashinfer-ai/flashinfer"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/flashinfer-ai/flashinfer"&gt;https://github.com/flashinfer-ai/flashinfer&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;FlashInfer: Kernel Library for LLM Serving&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:karpathy:llm.c:1757894400</ns0:id>
    <ns0:title>karpathy/llm.c</ns0:title>
    <ns0:link href="https://github.com/karpathy/llm.c"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/karpathy/llm.c"&gt;https://github.com/karpathy/llm.c&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;LLM training in simple, raw C/CUDA&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:nerfstudio-project:gsplat:1757894400</ns0:id>
    <ns0:title>nerfstudio-project/gsplat</ns0:title>
    <ns0:link href="https://github.com/nerfstudio-project/gsplat"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/nerfstudio-project/gsplat"&gt;https://github.com/nerfstudio-project/gsplat&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;CUDA accelerated rasterization of gaussian splatting&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:rahul-goel:fused-ssim:1757894400</ns0:id>
    <ns0:title>rahul-goel/fused-ssim</ns0:title>
    <ns0:link href="https://github.com/rahul-goel/fused-ssim"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/rahul-goel/fused-ssim"&gt;https://github.com/rahul-goel/fused-ssim&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Lightning fast differentiable SSIM.&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:siboehm:SGEMM_CUDA:1757894400</ns0:id>
    <ns0:title>siboehm/SGEMM_CUDA</ns0:title>
    <ns0:link href="https://github.com/siboehm/SGEMM_CUDA"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/siboehm/SGEMM_CUDA"&gt;https://github.com/siboehm/SGEMM_CUDA&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Fast CUDA matrix multiplication from scratch&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>urn:github:thu-ml:SageAttention:1757894400</ns0:id>
    <ns0:title>thu-ml/SageAttention</ns0:title>
    <ns0:link href="https://github.com/thu-ml/SageAttention"/>
    <ns0:updated>2025-09-15T00:00:00</ns0:updated>
    <ns0:content type="html">&lt;div&gt;
&lt;div&gt;&lt;strong&gt;URL:&lt;/strong&gt; &lt;a href="https://github.com/thu-ml/SageAttention"&gt;https://github.com/thu-ml/SageAttention&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Language:&lt;/strong&gt; cuda&lt;/div&gt;
&lt;hr&gt;
&lt;div&gt;Quantized Attention achieves speedup of 2-5x and 3-11x compared to FlashAttention and xformers, without lossing end-to-end metrics across language, image, and video models.&lt;/div&gt;
&lt;/div&gt;</ns0:content>
  </ns0:entry>
</ns0:feed>