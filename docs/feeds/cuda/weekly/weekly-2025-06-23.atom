<?xml version='1.0' encoding='utf-8'?>
<ns0:feed xmlns:ns0="http://www.w3.org/2005/Atom" xml:lang="en">
  <ns0:id>https://aazw.github.io/github-trending-feeds/feeds/cuda/weekly.atom</ns0:id>
  <ns0:title>GitHub Trending - cuda (weekly)</ns0:title>
  <ns0:link href="https://aazw.github.io/github-trending-feeds/feeds/cuda/weekly.atom" rel="self"/>
  <ns0:link href="https://aazw.github.io/github-trending-feeds/" rel="alternate"/>
  <ns0:icon>https://github.githubassets.com/favicons/favicon.svg</ns0:icon>
  <ns0:updated>2025-06-23T00:00:00</ns0:updated>
  <ns0:author>
    <ns0:name>aazw</ns0:name>
  </ns0:author>
  <ns0:entry>
    <ns0:id>https://github.com/Dao-AILab/causal-conv1d#1750636800</ns0:id>
    <ns0:title>https://github.com/Dao-AILab/causal-conv1d</ns0:title>
    <ns0:link href="https://github.com/Dao-AILab/causal-conv1d"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">Causal depthwise conv1d in CUDA, with a PyTorch interface</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/HazyResearch/ThunderKittens#1750636800</ns0:id>
    <ns0:title>https://github.com/HazyResearch/ThunderKittens</ns0:title>
    <ns0:link href="https://github.com/HazyResearch/ThunderKittens"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">Tile primitives for speedy kernels</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/HigherOrderCO/HVM#1750636800</ns0:id>
    <ns0:title>https://github.com/HigherOrderCO/HVM</ns0:title>
    <ns0:link href="https://github.com/HigherOrderCO/HVM"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">A massively parallel, optimal functional runtime in Rust</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/Infatoshi/cuda-course#1750636800</ns0:id>
    <ns0:title>https://github.com/Infatoshi/cuda-course</ns0:title>
    <ns0:link href="https://github.com/Infatoshi/cuda-course"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text"></ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/NVIDIA/CUDALibrarySamples#1750636800</ns0:id>
    <ns0:title>https://github.com/NVIDIA/CUDALibrarySamples</ns0:title>
    <ns0:link href="https://github.com/NVIDIA/CUDALibrarySamples"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">CUDA Library Samples</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/NVIDIA/nccl-tests#1750636800</ns0:id>
    <ns0:title>https://github.com/NVIDIA/nccl-tests</ns0:title>
    <ns0:link href="https://github.com/NVIDIA/nccl-tests"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">NCCL Tests</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/NVlabs/instant-ngp#1750636800</ns0:id>
    <ns0:title>https://github.com/NVlabs/instant-ngp</ns0:title>
    <ns0:link href="https://github.com/NVlabs/instant-ngp"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">Instant neural graphics primitives: lightning fast NeRF and more</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/PaddlePaddle/FastDeploy#1750636800</ns0:id>
    <ns0:title>https://github.com/PaddlePaddle/FastDeploy</ns0:title>
    <ns0:link href="https://github.com/PaddlePaddle/FastDeploy"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">Large Language Model Deployment Toolkit</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/camenduru/simple-knn#1750636800</ns0:id>
    <ns0:title>https://github.com/camenduru/simple-knn</ns0:title>
    <ns0:link href="https://github.com/camenduru/simple-knn"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text"></ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/computerhistory/AlexNet-Source-Code#1750636800</ns0:id>
    <ns0:title>https://github.com/computerhistory/AlexNet-Source-Code</ns0:title>
    <ns0:link href="https://github.com/computerhistory/AlexNet-Source-Code"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">This package contains the original 2012 AlexNet code.</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/deepseek-ai/DeepEP#1750636800</ns0:id>
    <ns0:title>https://github.com/deepseek-ai/DeepEP</ns0:title>
    <ns0:link href="https://github.com/deepseek-ai/DeepEP"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">DeepEP: an efficient expert-parallel communication library</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/deepseek-ai/FlashMLA#1750636800</ns0:id>
    <ns0:title>https://github.com/deepseek-ai/FlashMLA</ns0:title>
    <ns0:link href="https://github.com/deepseek-ai/FlashMLA"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">FlashMLA: Efficient MLA decoding kernels</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/flashinfer-ai/flashinfer#1750636800</ns0:id>
    <ns0:title>https://github.com/flashinfer-ai/flashinfer</ns0:title>
    <ns0:link href="https://github.com/flashinfer-ai/flashinfer"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">FlashInfer: Kernel Library for LLM Serving</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/karpathy/llm.c#1750636800</ns0:id>
    <ns0:title>https://github.com/karpathy/llm.c</ns0:title>
    <ns0:link href="https://github.com/karpathy/llm.c"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">LLM training in simple, raw C/CUDA</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/mit-han-lab/torchsparse#1750636800</ns0:id>
    <ns0:title>https://github.com/mit-han-lab/torchsparse</ns0:title>
    <ns0:link href="https://github.com/mit-han-lab/torchsparse"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">[MICRO'23, MLSys'22] TorchSparse: Efficient Training and Inference Framework for Sparse Convolution on GPUs.</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/nerfstudio-project/gsplat#1750636800</ns0:id>
    <ns0:title>https://github.com/nerfstudio-project/gsplat</ns0:title>
    <ns0:link href="https://github.com/nerfstudio-project/gsplat"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">CUDA accelerated rasterization of gaussian splatting</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/rahul-goel/fused-ssim#1750636800</ns0:id>
    <ns0:title>https://github.com/rahul-goel/fused-ssim</ns0:title>
    <ns0:link href="https://github.com/rahul-goel/fused-ssim"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">Lightning fast differentiable SSIM.</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/rapidsai/cugraph#1750636800</ns0:id>
    <ns0:title>https://github.com/rapidsai/cugraph</ns0:title>
    <ns0:link href="https://github.com/rapidsai/cugraph"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">cuGraph - RAPIDS Graph Analytics Library</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/rapidsai/cuvs#1750636800</ns0:id>
    <ns0:title>https://github.com/rapidsai/cuvs</ns0:title>
    <ns0:link href="https://github.com/rapidsai/cuvs"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">cuVS - a library for vector search and clustering on the GPU</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/thu-ml/SageAttention#1750636800</ns0:id>
    <ns0:title>https://github.com/thu-ml/SageAttention</ns0:title>
    <ns0:link href="https://github.com/thu-ml/SageAttention"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">Quantized Attention achieves speedup of 2-5x and 3-11x compared to FlashAttention and xformers, without lossing end-to-end metrics across language, image, and video models.</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/thu-ml/SpargeAttn#1750636800</ns0:id>
    <ns0:title>https://github.com/thu-ml/SpargeAttn</ns0:title>
    <ns0:link href="https://github.com/thu-ml/SpargeAttn"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">SpargeAttention: A training-free sparse attention that can accelerate any model inference.</ns0:content>
  </ns0:entry>
</ns0:feed>