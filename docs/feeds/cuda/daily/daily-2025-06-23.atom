<?xml version='1.0' encoding='utf-8'?>
<ns0:feed xmlns:ns0="http://www.w3.org/2005/Atom" xml:lang="en">
  <ns0:id>https://aazw.github.io/github-trending-feeds/feeds/cuda/daily.atom</ns0:id>
  <ns0:title>GitHub Trending - cuda (daily)</ns0:title>
  <ns0:link href="https://aazw.github.io/github-trending-feeds/feeds/cuda/daily.atom" rel="self"/>
  <ns0:link href="https://aazw.github.io/github-trending-feeds/" rel="alternate"/>
  <ns0:icon>https://github.githubassets.com/favicons/favicon.svg</ns0:icon>
  <ns0:updated>2025-06-23T00:00:00</ns0:updated>
  <ns0:author>
    <ns0:name>aazw</ns0:name>
  </ns0:author>
  <ns0:entry>
    <ns0:id>https://github.com/HazyResearch/ThunderKittens#1750636800</ns0:id>
    <ns0:title>https://github.com/HazyResearch/ThunderKittens</ns0:title>
    <ns0:link href="https://github.com/HazyResearch/ThunderKittens"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">Tile primitives for speedy kernels</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/NVIDIA/cub#1750636800</ns0:id>
    <ns0:title>https://github.com/NVIDIA/cub</ns0:title>
    <ns0:link href="https://github.com/NVIDIA/cub"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">[ARCHIVED] Cooperative primitives for CUDA C++. See https://github.com/NVIDIA/cccl</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/NVIDIA/nvbench#1750636800</ns0:id>
    <ns0:title>https://github.com/NVIDIA/nvbench</ns0:title>
    <ns0:link href="https://github.com/NVIDIA/nvbench"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">CUDA Kernel Benchmarking Library</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/NVlabs/instant-ngp#1750636800</ns0:id>
    <ns0:title>https://github.com/NVlabs/instant-ngp</ns0:title>
    <ns0:link href="https://github.com/NVlabs/instant-ngp"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">Instant neural graphics primitives: lightning fast NeRF and more</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/ashawkey/diff-gaussian-rasterization#1750636800</ns0:id>
    <ns0:title>https://github.com/ashawkey/diff-gaussian-rasterization</ns0:title>
    <ns0:link href="https://github.com/ashawkey/diff-gaussian-rasterization"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text"></ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/flashinfer-ai/flashinfer#1750636800</ns0:id>
    <ns0:title>https://github.com/flashinfer-ai/flashinfer</ns0:title>
    <ns0:link href="https://github.com/flashinfer-ai/flashinfer"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">FlashInfer: Kernel Library for LLM Serving</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/karpathy/llm.c#1750636800</ns0:id>
    <ns0:title>https://github.com/karpathy/llm.c</ns0:title>
    <ns0:link href="https://github.com/karpathy/llm.c"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">LLM training in simple, raw C/CUDA</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/nerfstudio-project/gsplat#1750636800</ns0:id>
    <ns0:title>https://github.com/nerfstudio-project/gsplat</ns0:title>
    <ns0:link href="https://github.com/nerfstudio-project/gsplat"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">CUDA accelerated rasterization of gaussian splatting</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/rapidsai/cugraph#1750636800</ns0:id>
    <ns0:title>https://github.com/rapidsai/cugraph</ns0:title>
    <ns0:link href="https://github.com/rapidsai/cugraph"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">cuGraph - RAPIDS Graph Analytics Library</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/rapidsai/cugraph-gnn#1750636800</ns0:id>
    <ns0:title>https://github.com/rapidsai/cugraph-gnn</ns0:title>
    <ns0:link href="https://github.com/rapidsai/cugraph-gnn"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text"></ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/rapidsai/cuvs#1750636800</ns0:id>
    <ns0:title>https://github.com/rapidsai/cuvs</ns0:title>
    <ns0:link href="https://github.com/rapidsai/cuvs"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">cuVS - a library for vector search and clustering on the GPU</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/rapidsai/raft#1750636800</ns0:id>
    <ns0:title>https://github.com/rapidsai/raft</ns0:title>
    <ns0:link href="https://github.com/rapidsai/raft"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">RAFT contains fundamental widely-used algorithms and primitives for machine learning and information retrieval. The algorithms are CUDA-accelerated and form building blocks for more easily writing high performance applications.</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/tgale96/grouped_gemm#1750636800</ns0:id>
    <ns0:title>https://github.com/tgale96/grouped_gemm</ns0:title>
    <ns0:link href="https://github.com/tgale96/grouped_gemm"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">PyTorch bindings for CUTLASS grouped GEMM.</ns0:content>
  </ns0:entry>
  <ns0:entry>
    <ns0:id>https://github.com/thu-ml/SageAttention#1750636800</ns0:id>
    <ns0:title>https://github.com/thu-ml/SageAttention</ns0:title>
    <ns0:link href="https://github.com/thu-ml/SageAttention"/>
    <ns0:updated>2025-06-23T00:00:00</ns0:updated>
    <ns0:content type="text">Quantized Attention achieves speedup of 2-5x and 3-11x compared to FlashAttention and xformers, without lossing end-to-end metrics across language, image, and video models.</ns0:content>
  </ns0:entry>
</ns0:feed>